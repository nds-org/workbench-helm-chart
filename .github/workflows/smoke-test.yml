name: Smoke Test

on: 
  pull_request:
    branches:
      - main
      - develop
  push:
    branches:
      - main
      - develop

jobs:
  helm-lint:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: v3.10.0

      - name: Fetch helm chart dependencies
        run: |
          helm dep up

      - name: Run helm lint
        run: |
          helm lint

  dev-workflow:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: v3.10.0

      - name: Create kind cluster
        uses: helm/kind-action@v1.4.0

      - name: Setup environment
        run: |
          cat .env | sed -e 's/WHICH_ARGS=-s/WHICH_ARGS=/' -e 's/REALM_IMPORT=true/REALM_IMPORT=false/' -e "s/KUBE_CONTEXT=docker-desktop/KUBE_CONTEXT=$(kubectl config current-context)/" > .env
          cat .env

      - name: Clone repos, compile source, fetch deps, and install (localdev + ci + livereload)
        run: |
          make check_required
          make dep
          make clone
          make compile
          helm upgrade --debug --install workbench -n workbench . --create-namespace -f values.localdev.yaml -f values.ci.yaml -f values.localdev.livereload.yaml

      - name: Output Helm chart templates (for debugging)
        run: |
          helm template --debug --dry-run workbench -n workbench . -f values.localdev.yaml -f values.ci.yaml -f values.localdev.livereload.yaml

      - name: Wait for NFS Server to start
        run: |
          kubectl wait pods -n workbench -lapp=nfs-server-provisioner --for condition=Ready --timeout=90s || kubectl describe pod -lapp=nfs-server-provisioner -n workbench && kubectl logs -lapp=nfs-server-provisioner -n workbench
          kubectl get pods -n workbench

      - name: Wait for Redis + OAuth2 Proxy to start
        run: |
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=master --for condition=Ready --timeout=90s || kubectl describe pod -lapp.kubernetes.io/component=master -n workbench && kubectl logs -lapp.kubernetes.io/component=master -n workbench
          kubectl get pods -n workbench
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=oauth2-proxy --for condition=Ready --timeout=300s || kubectl describe pod -lapp.kubernetes.io/component=oauth2-proxy -n workbench && kubectl logs -lapp.kubernetes.io/component=oauth2-proxy -n workbench
          kubectl get pods -n workbench

      - name: Wait for MongoDB + Workbench to start
        run: |
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=mongodb --for condition=Ready --timeout=90s || kubectl describe pod -lapp.kubernetes.io/component=mongodb -n workbench && kubectl logs -lapp.kubernetes.io/component=mongodb -n workbench
          kubectl get pods -n workbench
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=workbench --for condition=Ready --timeout=300s || kubectl describe pod -lapp.kubernetes.io/component=workbench -n workbench && kubectl logs -lapp.kubernetes.io/component=workbench -n workbench -c wait-for-oauth2-proxy && kubectl logs -lapp.kubernetes.io/component=workbench -n workbench -c webui && kubectl logs -lapp.kubernetes.io/component=workbench -n workbench -c apiserver
          kubectl get pods -n workbench

      - name: Show Workbench status
        run: |
          make status

      - name: Describe Workbench Pod (view Pod events)
        run: |
          make describe

      - name: Rebuild Docker images
        run: |
          make build

      - name: Restart Workbench Pod
        run: |
          make restart

      - name: Run make uninstall
        run: |
          make uninstall

      - name: Run make clean
        run: |
          make clean

      - name: Run make clean_all
        run: |
          make clean_all



  smoke-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: v3.10.0

      - name: Fetch helm chart dependencies
        run: |
          helm dep up

      - name: Create kind cluster
        uses: helm/kind-action@v1.4.0

      - name: Run helm template (localdev + ci)
        run: |
          helm template -n workbench workbench . -f values.localdev.yaml -f values.ci.yaml --debug --dry-run

      - name: Run helm install (localdev + ci)
        run: |
          helm upgrade --install -n workbench workbench . --create-namespace -f values.localdev.yaml -f values.ci.yaml --debug

      - name: Wait for NFS Server to start
        run: |
          kubectl wait pods -n workbench -lapp=nfs-server-provisioner --for condition=Ready --timeout=90s || kubectl describe pod -lapp=nfs-server-provisioner -n workbench && kubectl logs -lapp=nfs-server-provisioner -n workbench
          kubectl get pods -n workbench 

      - name: Wait for Redis + OAuth2 Proxy to start
        run: |
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=master --for condition=Ready --timeout=90s || kubectl describe pod -lapp.kubernetes.io/component=master -n workbench && kubectl logs -lapp.kubernetes.io/component=master -n workbench
          kubectl get pods -n workbench
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=oauth2-proxy --for condition=Ready --timeout=300s || kubectl describe pod -lapp.kubernetes.io/component=oauth2-proxy -n workbench && kubectl logs -lapp.kubernetes.io/component=oauth2-proxy -n workbench
          kubectl get pods -n workbench

      - name: Wait for MongoDB + Workbench to start
        run: |
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=mongodb --for condition=Ready --timeout=90s || kubectl describe pod -lapp.kubernetes.io/component=mongodb -n workbench && kubectl logs -lapp.kubernetes.io/component=mongodb -n workbench
          kubectl get pods -n workbench
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=workbench --for condition=Ready --timeout=300s || kubectl describe pod -lapp.kubernetes.io/component=workbench -n workbench && kubectl logs -lapp.kubernetes.io/component=workbench -n workbench -c wait-for-oauth2-proxy && kubectl logs -lapp.kubernetes.io/component=workbench -n workbench -c webui && kubectl logs -lapp.kubernetes.io/component=workbench -n workbench -c apiserver
          kubectl get pods -n workbench

      - name: "Test Connection - Ingress -> OAuth2 Proxy"
        run: |
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=controller --for condition=Ready --timeout 10s
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=oauth2-proxy --for condition=Ready --timeout 10s
          sleep 2
          kubectl exec -it deploy/workbench -c apiserver -n workbench -- curl --insecure https://workbench-ingress-nginx-controller.workbench.svc.cluster.local/oauth2/auth

      - name: "Test Connection - Ingress -> Workbench API"
        run: |
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=controller --for condition=Ready --timeout 10s
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=workbench --for condition=Ready --timeout 10s
          sleep 2
          kubectl exec -it deploy/workbench -c apiserver -n workbench -- curl --fail --insecure https://workbench-ingress-nginx-controller.workbench.svc.cluster.local/api/v1/version

      - name: "Test Connection - Workbench API -> MongoDB"
        run: |
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=controller --for condition=Ready --timeout 15s
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=workbench --for condition=Ready --timeout 10s
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=mongodb --for condition=Ready --timeout 10s
          sleep 2
          kubectl exec -it deploy/workbench -c apiserver -n workbench -- curl --fail --insecure https://workbench-ingress-nginx-controller.workbench.svc.cluster.local/api/v1/services

      - name: "Test Connection - Ingress -> WebUI"
        run: |
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=controller --for condition=Ready --timeout 10s
          kubectl wait pods -n workbench -lapp.kubernetes.io/component=workbench --for condition=Ready --timeout 10s
          sleep 2
          kubectl exec -it deploy/workbench -c apiserver -n workbench -- curl --fail --insecure https://workbench-ingress-nginx-controller.workbench.svc.cluster.local/frontend.json

      - name: "Cleanup: Uninstall Helm release"
        if: ${{ always() }}
        run: |
          helm uninstall workbench -n workbench

      - name: "Cleanup: Delete namespace"
        if: ${{ always() }}
        run: |
          kubectl delete namespace workbench
